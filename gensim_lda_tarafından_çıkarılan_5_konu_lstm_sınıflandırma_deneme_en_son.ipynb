{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhbUbchETNsT"
      },
      "outputs": [],
      "source": [
        " # Veri yapıları ile çalışmak için pandas modülü.\n",
        "from sklearn import metrics\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "RqS3Fpi8TWeb",
        "outputId": "daa306fc-1daf-44d0-9af0-93b735c5ee13"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'df_5_toplam.xlsx'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-3ce29a9c2bee>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'df_5_toplam.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Unnamed: 0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m         raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1494\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1495\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1496\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1497\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1498\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1371\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1372\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m     ) as handle:\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    866\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    869\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'df_5_toplam.xlsx'"
          ]
        }
      ],
      "source": [
        "df = pd.read_excel('df_5_toplam.xlsx')\n",
        "df.drop(columns=['Unnamed: 0'],inplace=True)\n",
        "df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UIIFp5IFTNsX"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer # Makinenin yazıyı anlayabilmesi için Tokenizer ile veri setinde kullanılan en çok 50000 kelime ile bir sözlük oluşturulur.\n",
        "\n",
        "tokenizer = Tokenizer(num_words=50000) # sözlük oluşturulur.\n",
        "tokenizer.fit_on_texts(df['Yazı']) # yazılar tokene dönüştürülür."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T03bljzxTNsX",
        "outputId": "9e3d29a3-8b3d-4277-f409-2108b0dda221"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2261"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Verimiz için bir cümle uzunluğu hesaplanır.\n",
        " # Dizi işlemleri için numpy modülü.\n",
        "\n",
        "# toplam token sayısı\n",
        "num_tokens = [len(tokens) for tokens in df['Yazı']]\n",
        "num_tokens = np.array(num_tokens)\n",
        "\n",
        "# max token sayısı\n",
        "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
        "max_tokens = int(max_tokens)\n",
        "max_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u78iYi7hTNsY"
      },
      "outputs": [],
      "source": [
        "input_dim = 50000  # Embedding layer's input dimension\n",
        "embedding_dim = 100\n",
        "output_dim = 5\n",
        "epochs = 30\n",
        "units = 512  # GRU units"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vx2MefA5TNsY",
        "outputId": "cab1995c-455f-439d-f85b-85b5480e676e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(7721, 2261) (7721, 5)\n",
            "(2574, 2261) (2574, 5)\n"
          ]
        }
      ],
      "source": [
        "# Örnek veri, x_rus ve y_rus (Bu verilerin yüklenmiş ve işlenmiş olduğunu varsayıyoruz)\n",
        "# Not: Gerçek veri ile değiştirin\n",
        "x_rus = np.random.randint(0, input_dim, size=(10295, 2261))  # Örnek veri\n",
        "y_rus = np.random.randint(output_dim, size=10295)  # Örnek veri\n",
        "y_rus = tf.keras.utils.to_categorical(y_rus, num_classes=output_dim)\n",
        "\n",
        "# Verilerin Eğitim ve Test Olarak Bölünmesi\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_rus, y_rus, test_size=0.25, random_state=42)\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSX-tM8MTNsY"
      },
      "outputs": [],
      "source": [
        "x_train = pad_sequences(x_train, maxlen=2261, padding='post', truncating='post')\n",
        "x_test = pad_sequences(x_test, maxlen=2261, padding='post', truncating='post')\n",
        "\n",
        "# Giriş verisini doğrulama ve ölçeklendirme\n",
        "x_train = np.clip(x_train, 0, input_dim - 1)\n",
        "x_test = np.clip(x_test, 0, input_dim - 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npVX0IodTNsZ"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras # yapay sinir ağı kullanmak için keras yüklenir.\n",
        "from math import exp\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, GRU\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "#num_words kelime sayıları, embedding_size kelime vektör uzunluğu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5gOS9Ac3Ln-",
        "outputId": "b3ea4c0a-972c-47ab-ba8d-f25c7a78d655"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\anacond\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "sonuçlar_df = pd.DataFrame()\n",
        "import h5py\n",
        "# Farklı epochs ve units kombinasyonlarını deneme\n",
        "for epochs in [30]:\n",
        "    for units in [512]:\n",
        "        # Modeli Oluşturma\n",
        "        model = Sequential([\n",
        "            Embedding(input_dim=input_dim, output_dim=embedding_dim, input_length=2261),\n",
        "            LSTM(units=units),\n",
        "            Dense(output_dim, activation='softmax')\n",
        "        ])\n",
        "\n",
        "        # Modeli Derleme\n",
        "        model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
        "\n",
        "        # Callbacks\n",
        "        #callbacks = [ModelCheckpoint(filepath='mymodel.keras', monitor='val_loss', mode='min',\n",
        "                                    # save_best_only=True, save_weights_only=False, verbose=1)]\n",
        "\n",
        "        # Eğitim başlangıç zamanı\n",
        "        baslangic_zamani = time.time()\n",
        "\n",
        "        # Modeli Eğitme\n",
        "        history = model.fit(x=x_train, y=y_train, epochs=epochs, batch_size=512,\n",
        "                            validation_data=(x_test, y_test), shuffle=False, verbose=0)\n",
        "\n",
        "        # Eğitim bitiş zamanı\n",
        "        bitis_zamani = time.time()\n",
        "        sure = bitis_zamani - baslangic_zamani\n",
        "\n",
        "        # Son epoch'un doğrulama kaybı\n",
        "        last_val_loss = history.history['val_loss'][-1]\n",
        "        print(f'Last Epoch Validation Loss = {last_val_loss}')\n",
        "\n",
        "        # Modeli Değerlendirme\n",
        "        loss = model.evaluate(x_test, y_test, batch_size=64)\n",
        "        print(f\"\\nepochs={epochs}, units={units} => test loss: {loss}\")\n",
        "\n",
        "        # Tahminleri Al\n",
        "        eğitim_predict = model.predict(x_train)\n",
        "        test_predict = model.predict(x_test)\n",
        "\n",
        "        # MSE ve RMSE Hesaplama\n",
        "        mean_squared_error_test = mean_squared_error(np.argmax(y_test, axis=1), np.argmax(test_predict, axis=1))\n",
        "        test_rmse = np.sqrt(mean_squared_error_test)\n",
        "\n",
        "        mean_squared_error_eğitim = mean_squared_error(np.argmax(y_train, axis=1), np.argmax(eğitim_predict, axis=1))\n",
        "        eğitim_rmse = np.sqrt(mean_squared_error_eğitim)\n",
        "\n",
        "        # Sonuçları DataFrame'e Ekleme\n",
        "        sonuçlar_df = pd.concat([sonuçlar_df, pd.DataFrame({\n",
        "            'epochs': [epochs],\n",
        "            'units': [units],\n",
        "            'mean_squared_error_test': [mean_squared_error_test],\n",
        "            'mean_squared_error_eğitim': [mean_squared_error_eğitim],\n",
        "            'test_rmse': [test_rmse],\n",
        "            'eğitim_rmse': [eğitim_rmse],\n",
        "            'val_loss': [last_val_loss],\n",
        "            'sure': [sure]\n",
        "        })], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUJmBKB-6X4g"
      },
      "outputs": [],
      "source": [
        "y_pred_probs = model.predict(x_test)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wcwVeiav6cHM"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qz7bzae6d35"
      },
      "outputs": [],
      "source": [
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "print(\"Doğruluk Skoru:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ve-psyj-6o7r"
      },
      "outputs": [],
      "source": [
        "loss= model.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yrq_z58g6qW9"
      },
      "outputs": [],
      "source": [
        "# Tahminler ve gerçek etiketleri bir DataFrame'e yerleştirin\n",
        "\n",
        "\n",
        "# Doğruluk skorunu DataFrame'e ekleyin\n",
        "accuracy_df = pd.DataFrame({'Doğruluk Skoru': [accuracy]})\n",
        "\n",
        "sonuçlar_df=pd.concat([sonuçlar_df, accuracy_df], axis=1)\n",
        "\n",
        "# DataFrame'leri bir Excel dosyasına yazın\n",
        "with pd.ExcelWriter('/content/LSTM_results.xlsx') as writer:\n",
        "    sonuçlar_df.to_excel(writer, index=False)\n",
        "\n",
        "print(\"Sonuçlar Excel dosyasına kaydedildi.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fud0wI9v6uRY"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download('/content/LSTM_results.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-OIlkmct0XP2"
      },
      "outputs": [],
      "source": [
        "sonuçlar_df"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "toc-autonumbering": false,
    "toc-showtags": false
  },
  "nbformat": 4,
  "nbformat_minor": 0
}